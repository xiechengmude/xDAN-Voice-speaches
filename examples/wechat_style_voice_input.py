#!/usr/bin/env python3
"""
å¾®ä¿¡é£æ ¼çš„è¯­éŸ³è¾“å…¥è½¬æ–‡å­—åŠŸèƒ½å®ç°
éå®æ—¶è¯­éŸ³è¯†åˆ«ï¼Œå½•åˆ¶å®Œæˆåè½¬æ–‡å­—
"""

import os
import httpx
import pyaudio
import wave
import threading
import time
from pathlib import Path
from typing import Optional, Callable
from datetime import datetime

# é…ç½®
SPEACHES_BASE_URL = os.getenv("SPEACHES_BASE_URL", "http://localhost:8000")
ASR_MODEL = "Systran/faster-distil-whisper-large-v3"  # æ¨èçš„æ¨¡å‹

class WeChatStyleVoiceInput:
    """
    å¾®ä¿¡é£æ ¼çš„è¯­éŸ³è¾“å…¥å®ç°
    - æŒ‰ä½å½•éŸ³
    - æ¾å¼€åœæ­¢
    - è‡ªåŠ¨è½¬æ–‡å­—
    """
    
    def __init__(self, 
                 base_url: str = SPEACHES_BASE_URL,
                 model: str = ASR_MODEL,
                 max_duration: int = 60):  # æœ€é•¿å½•éŸ³æ—¶é—´ï¼ˆç§’ï¼‰
        self.base_url = base_url
        self.model = model
        self.max_duration = max_duration
        self.is_recording = False
        self.audio_data = []
        self.client = httpx.Client(timeout=30.0)
        
        # éŸ³é¢‘å‚æ•°ï¼ˆå¾®ä¿¡æ ‡å‡†ï¼‰
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000  # 16kHz é‡‡æ ·ç‡
        self.chunk = 1024
        
        # åˆå§‹åŒ– PyAudio
        self.audio = pyaudio.PyAudio()
        
    def start_recording(self, on_start: Optional[Callable] = None):
        """å¼€å§‹å½•éŸ³"""
        if self.is_recording:
            return
            
        self.is_recording = True
        self.audio_data = []
        
        if on_start:
            on_start()
            
        # åœ¨æ–°çº¿ç¨‹ä¸­å½•éŸ³
        self.record_thread = threading.Thread(target=self._record_audio)
        self.record_thread.start()
        
    def stop_recording(self) -> Optional[str]:
        """
        åœæ­¢å½•éŸ³å¹¶è¿”å›è¯†åˆ«ç»“æœ
        
        Returns:
            è¯†åˆ«çš„æ–‡å­—ï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        if not self.is_recording:
            return None
            
        self.is_recording = False
        self.record_thread.join()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å½•éŸ³æ•°æ®
        if not self.audio_data:
            print("æ²¡æœ‰å½•éŸ³æ•°æ®")
            return None
            
        # ä¿å­˜ä¸ºä¸´æ—¶ WAV æ–‡ä»¶
        temp_file = self._save_audio()
        
        try:
            # è°ƒç”¨ ASR è¯†åˆ«
            result = self._transcribe_audio(temp_file)
            return result
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file.exists():
                temp_file.unlink()
                
    def _record_audio(self):
        """å½•éŸ³çº¿ç¨‹"""
        stream = self.audio.open(
            format=self.format,
            channels=self.channels,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunk
        )
        
        print("å¼€å§‹å½•éŸ³...")
        start_time = time.time()
        
        try:
            while self.is_recording:
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æ—¶é•¿
                if time.time() - start_time > self.max_duration:
                    print(f"è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿ {self.max_duration} ç§’")
                    self.is_recording = False
                    break
                    
                # è¯»å–éŸ³é¢‘æ•°æ®
                data = stream.read(self.chunk, exception_on_overflow=False)
                self.audio_data.append(data)
                
        finally:
            stream.stop_stream()
            stream.close()
            
        duration = time.time() - start_time
        print(f"å½•éŸ³ç»“æŸï¼Œæ—¶é•¿: {duration:.1f} ç§’")
        
    def _save_audio(self) -> Path:
        """ä¿å­˜éŸ³é¢‘ä¸º WAV æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        temp_file = Path(f"voice_input_{timestamp}.wav")
        
        with wave.open(str(temp_file), 'wb') as wf:
            wf.setnchannels(self.channels)
            wf.setsampwidth(self.audio.get_sample_size(self.format))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(self.audio_data))
            
        return temp_file
        
    def _transcribe_audio(self, audio_file: Path) -> Optional[str]:
        """è°ƒç”¨ Speaches ASR è¯†åˆ«éŸ³é¢‘"""
        try:
            with open(audio_file, 'rb') as f:
                files = {'file': (audio_file.name, f, 'audio/wav')}
                data = {
                    'model': self.model,
                    'language': 'zh',  # å¯ä»¥è®¾ç½®ä¸º auto è‡ªåŠ¨æ£€æµ‹
                    'response_format': 'json'
                }
                
                response = self.client.post(
                    f"{self.base_url}/v1/audio/transcriptions",
                    files=files,
                    data=data
                )
                
            if response.status_code == 200:
                result = response.json()
                return result.get('text', '')
            else:
                print(f"è¯†åˆ«å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"è¯†åˆ«é”™è¯¯: {e}")
            return None
            
    def close(self):
        """æ¸…ç†èµ„æº"""
        self.audio.terminate()
        self.client.close()


class VoiceInputUI:
    """ç®€å•çš„è¯­éŸ³è¾“å…¥ UI æ¨¡æ‹Ÿ"""
    
    def __init__(self):
        self.voice_input = WeChatStyleVoiceInput()
        
    def simulate_wechat_input(self):
        """æ¨¡æ‹Ÿå¾®ä¿¡è¯­éŸ³è¾“å…¥æµç¨‹"""
        print("\n=== å¾®ä¿¡é£æ ¼è¯­éŸ³è¾“å…¥ ===")
        print("ä½¿ç”¨è¯´æ˜:")
        print("- æŒ‰ Enter å¼€å§‹å½•éŸ³")
        print("- å†æŒ‰ Enter åœæ­¢å½•éŸ³")
        print("- è¾“å…¥ 'quit' é€€å‡º")
        print("-" * 40)
        
        while True:
            command = input("\næŒ‰ Enter å¼€å§‹å½•éŸ³ (æˆ–è¾“å…¥ 'quit' é€€å‡º): ")
            
            if command.lower() == 'quit':
                break
                
            # å¼€å§‹å½•éŸ³
            self.voice_input.start_recording(
                on_start=lambda: print("ğŸ¤ æ­£åœ¨å½•éŸ³... (æŒ‰ Enter åœæ­¢)")
            )
            
            # ç­‰å¾…ç”¨æˆ·åœæ­¢
            input()
            
            # åœæ­¢å½•éŸ³å¹¶è¯†åˆ«
            print("â¹ï¸  åœæ­¢å½•éŸ³ï¼Œæ­£åœ¨è¯†åˆ«...")
            text = self.voice_input.stop_recording()
            
            if text:
                print(f"\nğŸ“ è¯†åˆ«ç»“æœ: {text}")
            else:
                print("\nâŒ è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•")
                
        self.voice_input.close()
        print("\né€€å‡ºè¯­éŸ³è¾“å…¥")


# é«˜çº§åŠŸèƒ½ï¼šå¸¦å›è°ƒçš„è¯­éŸ³è¾“å…¥
class AdvancedVoiceInput(WeChatStyleVoiceInput):
    """
    é«˜çº§è¯­éŸ³è¾“å…¥ï¼Œæ”¯æŒå„ç§å›è°ƒå’Œäº‹ä»¶
    """
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.callbacks = {
            'on_recording_start': None,
            'on_recording_stop': None,
            'on_transcription_start': None,
            'on_transcription_complete': None,
            'on_error': None
        }
        
    def set_callback(self, event: str, callback: Callable):
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        if event in self.callbacks:
            self.callbacks[event] = callback
            
    def start_recording(self, on_start: Optional[Callable] = None):
        """å¼€å§‹å½•éŸ³ï¼ˆå¸¦å›è°ƒï¼‰"""
        super().start_recording(on_start)
        if self.callbacks['on_recording_start']:
            self.callbacks['on_recording_start']()
            
    def stop_recording(self) -> Optional[str]:
        """åœæ­¢å½•éŸ³å¹¶è¯†åˆ«ï¼ˆå¸¦å›è°ƒï¼‰"""
        if self.callbacks['on_recording_stop']:
            self.callbacks['on_recording_stop']()
            
        # åœæ­¢å½•éŸ³
        self.is_recording = False
        self.record_thread.join()
        
        if not self.audio_data:
            if self.callbacks['on_error']:
                self.callbacks['on_error']("æ²¡æœ‰å½•éŸ³æ•°æ®")
            return None
            
        # ä¿å­˜éŸ³é¢‘
        temp_file = self._save_audio()
        
        try:
            if self.callbacks['on_transcription_start']:
                self.callbacks['on_transcription_start']()
                
            # è¯†åˆ«
            result = self._transcribe_audio(temp_file)
            
            if result and self.callbacks['on_transcription_complete']:
                self.callbacks['on_transcription_complete'](result)
                
            return result
            
        except Exception as e:
            if self.callbacks['on_error']:
                self.callbacks['on_error'](str(e))
            return None
            
        finally:
            if temp_file.exists():
                temp_file.unlink()


# å®é™…åº”ç”¨ç¤ºä¾‹
def demo_voice_message():
    """æ¼”ç¤ºï¼šè¯­éŸ³æ¶ˆæ¯åŠŸèƒ½"""
    print("\n=== è¯­éŸ³æ¶ˆæ¯æ¼”ç¤º ===")
    
    voice_input = AdvancedVoiceInput()
    
    # è®¾ç½®å›è°ƒ
    voice_input.set_callback('on_recording_start', 
                           lambda: print("ğŸ”´ å½•éŸ³ä¸­..."))
    voice_input.set_callback('on_recording_stop', 
                           lambda: print("â¹ï¸  å½•éŸ³ç»“æŸ"))
    voice_input.set_callback('on_transcription_start', 
                           lambda: print("ğŸ”„ æ­£åœ¨è½¬æ–‡å­—..."))
    voice_input.set_callback('on_transcription_complete', 
                           lambda text: print(f"âœ… è½¬æ¢å®Œæˆ: {text}"))
    voice_input.set_callback('on_error', 
                           lambda err: print(f"âŒ é”™è¯¯: {err}"))
    
    # å½•åˆ¶è¯­éŸ³æ¶ˆæ¯
    print("\nè¯·è¯´ä¸€æ®µè¯ä½œä¸ºè¯­éŸ³æ¶ˆæ¯...")
    input("æŒ‰ Enter å¼€å§‹: ")
    
    voice_input.start_recording()
    
    input("æŒ‰ Enter ç»“æŸ: ")
    
    text = voice_input.stop_recording()
    
    if text:
        print(f"\nè¯­éŸ³æ¶ˆæ¯æ–‡å­—ç‰ˆ: {text}")
        # è¿™é‡Œå¯ä»¥å°†æ–‡å­—å‘é€å‡ºå»
        
    voice_input.close()


def demo_voice_search():
    """æ¼”ç¤ºï¼šè¯­éŸ³æœç´¢åŠŸèƒ½"""
    print("\n=== è¯­éŸ³æœç´¢æ¼”ç¤º ===")
    
    voice_input = WeChatStyleVoiceInput()
    
    print("è¯·è¯´å‡ºæ‚¨è¦æœç´¢çš„å†…å®¹...")
    input("æŒ‰ Enter å¼€å§‹: ")
    
    voice_input.start_recording()
    time.sleep(3)  # è‡ªåŠ¨ 3 ç§’ååœæ­¢
    
    search_query = voice_input.stop_recording()
    
    if search_query:
        print(f"\nğŸ” æœç´¢: {search_query}")
        # è¿™é‡Œå¯ä»¥æ‰§è¡Œæœç´¢æ“ä½œ
        
    voice_input.close()


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "demo":
        # è¿è¡Œæ¼”ç¤º
        demo_voice_message()
        demo_voice_search()
    else:
        # è¿è¡Œäº¤äº’å¼ç•Œé¢
        ui = VoiceInputUI()
        ui.simulate_wechat_input()